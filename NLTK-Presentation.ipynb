{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b05589f0-bc9f-4d3a-9b81-06ad5c99702b"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python's Natural Language Toolkit - NLTK\n",
    " ##### Keziah Sheldon, Eesha Das Gupta, Rachel Buttry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "abbbf0bb-9f2d-443a-a519-8a6471d0795f"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Natural Language Processing?\n",
    "\n",
    "[Wisdom of Chopra](http://wisdomofchopra.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c978d3f9-93c1-45ff-975b-ac796a1422ba"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLTK\n",
    "\"Natural language processing is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages. As such, NLP is related to the area of human–computer interaction.\"-[Wikipedia](https://en.wikipedia.org/wiki/Natural_language_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "92297adc-adad-4a7c-ab8f-5b88ff5b22fb"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#tweets = nltk.corpus.twitter_samples() \n",
    "#]print ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "62085755-f394-422d-a675-4e8cdf6b1469"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tokenizing\n",
    "\n",
    "* Tokenization is the first step of NLP (Natural Language Processing)\n",
    "* Split strings into substrings\n",
    "* Separate into sentences, identifies where they start and stop\n",
    "\n",
    "\n",
    "Tokenize by sentence:\n",
    "Doesn’t just depend on punctuation since recent decades have much more ambiguous punctuation usage (emoticons, abbreviations etc.)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "9169ad09-a6fc-4c66-bbe5-fef9e66c7859"
    }
   },
   "source": [
    ">>> text = “this’s a sent tokenize test. this is sent two. is this sent three? sent 4 is cool! Now it’s your turn.”\n",
    ">>> from nltk.tokenize import sent_tokenize\n",
    ">>> sent_tokenize_list = sent_tokenize(text)\n",
    ">>> sent_tokenize_list\n",
    "[“this’s a sent tokenize test.”, ‘this is sent two.’, ‘is this sent three?’, ‘sent 4 is cool!’, “Now it’s your turn.”]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fabb1615-376b-4b18-90e4-bfdb4fce8bda"
    }
   },
   "source": [
    "Tokenize by word: (simpler than sentence tokenizer)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0d428832-0e0e-401f-8744-db1b9fa2d03d"
    }
   },
   "source": [
    ">>> from nltk.tokenize import word_tokenize\n",
    ">>> word_tokenize(‘Hello World.’)\n",
    "[‘Hello’, ‘World’, ‘.’]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "78cd1ee7-a50f-412e-adf5-6035341a4c69"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part of Speech (POS) Tagging\n",
    "\n",
    "\n",
    "* POS is grammatical tagging\n",
    "* Separates into nouns, adjectives, verbs etc.\n",
    "* Can use pre-trained taggers or train yourself\n",
    "\n",
    "Types of POS tags:\n",
    "* JJ: adjective or numeral, ordinal\n",
    "* NNP: noun, proper, singular\n",
    "* IN: preposition or conjunction, subordinating\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "7fab5b42-dabe-48c8-8557-67edd7755575"
    }
   },
   "source": [
    ">>> text = nltk.word_tokenize(“Dive into NLTK: Part-of-speech tagging and POS Tagger”)\n",
    ">>> nltk.pos_tag(text)\n",
    "[(‘Dive’, ‘JJ’), (‘into’, ‘IN’), (‘NLTK’, ‘NNP’), (‘:’, ‘:’), (‘Part-of-speech’, ‘JJ’), (‘tagging’, ‘NN’), (‘and’, ‘CC’), (‘POS’, ‘NNP’), (‘Tagger’, ‘NNP’)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "92f780f0-b790-4b26-87bb-d934e3c7ef82"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stemming\n",
    "\n",
    "Stemming is the the process of reducing a word to its stem through basic suffix stripping. For instance, the stem of the word “lively” is “live”, so running a the statement “She acted lively while helping me today.” through a stemmer (after tokenizing), would return the stems ‘act’, ‘live’, and ‘help’ with their respective words, while the rest of the words would just return the initial input (the words were already at their stem). \n",
    "\n",
    "\n",
    "Some common stemmers:\n",
    "\n",
    "* Snowball : http://www.nltk.org/_modules/nltk/stem/snowball.html\n",
    "\n",
    "* Porter : http://www.nltk.org/_modules/nltk/stem/porter.html\n",
    "\n",
    "* Lancaster : http://www.nltk.org/_modules/nltk/stem/lancaster.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "da42cbda-6b5e-4854-9588-8a134e97b904"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stem of 'expectations' is 'expect'.\n"
     ]
    }
   ],
   "source": [
    "snowball = nltk.stem.snowball.EnglishStemmer()\n",
    "word = 'expectations'\n",
    "print \"The stem of '{}' is '{}'.\".format(word, snowball.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0ae3e29d-fe40-411c-ab42-5a2b09d79df4"
    }
   },
   "source": [
    "A problem that arises is that, for many cases, the stemmers will not return actual words. For instance, the stem of the words “excitement” and “excited” are both “excit”. Stemming is sufficient in many cases of interpreting the meaning of texts, but a better option in terms of meaning, is lemmatization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1bf0f027-a1ed-4740-9ba4-8771035a5656"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lemmatization\n",
    "Lemmatization, on the other hand, is the reducing of a word to a common base word, known as the lemma. For instance, the word “excitement” reduces to the lemma “excite”, but also the words “are”, “am” and “is” reduce to the lemma “be”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3bd3fdaf-fbbf-485a-b268-5c2918cc1125"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Text Classification\n",
    "\n",
    "Text Classification is the use of NLTK Classifiers to classify text into categories.\n",
    "\n",
    "\n",
    "NLTK Classifiers:\n",
    "\n",
    "\n",
    "* Naive Bayes Classifier\n",
    "\n",
    "\n",
    "* Maximum Entropy Classifier\n",
    "\n",
    "\n",
    "* Decision Tree\n",
    "\n",
    "\n",
    "* Scikit Learn Wrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "Bayes Theorem : \n",
    "\n",
    "$$ P(C|x) = \\frac{P(x|C) P(C)}{P(x)} $$\n",
    "\n",
    "Naive Bayes Classification :\n",
    "\n",
    "Based on the assumption that all features ${x_1, x_2,......,x_i}$ are conditionally independent, given the category C\n",
    "\n",
    "or, $$ P(x_i|x_1, x_2,..,x_(i-1),x(i+1),...,C) = P(x_i|C) $$\n",
    "\n",
    "Then, $P(C|x_1,x_2,....,x_i)$ can be computed using Bayes Theorem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Entropy Model\n",
    "\n",
    "The model considers probability distributions closest to empirical data and picks the one with highest entropy.\n",
    "\n",
    "### What does entropy mean?\n",
    "\n",
    "Entropy is measure of uncertainty or 'surprise' in the data. Assumption is that data is likely to have random, unknown elements.\n",
    "\n",
    "### What will have the highest entropy?\n",
    "\n",
    "Usually, uniform distribution will have the highest entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7c6c582e-7ee5-4fdc-8ef0-9839ffc562a7"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applications of Text Classification - \n",
    "\n",
    "\n",
    "* Analyzing and classifying emails, texts and chats for security purposes\n",
    "\n",
    "\n",
    "* Data acquisition from social media posts for advertising\n",
    "\n",
    "\n",
    "* Analysis of speech patterns and transcripts for academic research (grammar development, language research, psychology, etc.)\n",
    "\n",
    "\n",
    "* Integrating NLP techniques with Artificial Intelligence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "6ddad21f-79d6-414f-80f2-8f5fcd7dd99e"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbpresent": {
   "slides": {},
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
