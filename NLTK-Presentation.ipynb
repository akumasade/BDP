{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b05589f0-bc9f-4d3a-9b81-06ad5c99702b"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python's Natural Language Toolkit - NLTK\n",
    " ##### Keziah Sheldon, Eesha Das Gupta, Rachel Buttry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "abbbf0bb-9f2d-443a-a519-8a6471d0795f"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Natural Language Processing?\n",
    "\n",
    "\"Natural language processing is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages.\" -[Wikipedia](https://en.wikipedia.org/wiki/Natural_language_processing)\n",
    "\n",
    "Link: [Wisdom of Chopra](http://wisdomofchopra.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c978d3f9-93c1-45ff-975b-ac796a1422ba"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLTK\n",
    "\"NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.\" \n",
    "\n",
    "[Read More](http://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "62085755-f394-422d-a675-4e8cdf6b1469"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tokenizing\n",
    "\n",
    "* Tokenization is the first step of NLP (Natural Language Processing)\n",
    "* Split strings into substrings\n",
    "* Separate into sentences, identifies where they start and stop\n",
    "\n",
    "\n",
    "Tokenize by sentence:\n",
    "Doesn’t just depend on punctuation since recent decades have much more ambiguous punctuation usage (emoticons, abbreviations etc.)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "9169ad09-a6fc-4c66-bbe5-fef9e66c7859"
    }
   },
   "source": [
    ">>> text = “this’s a sent tokenize test. this is sent two. is this sent three? sent 4 is cool! Now it’s your turn.”\n",
    ">>> from nltk.tokenize import sent_tokenize\n",
    ">>> sent_tokenize_list = sent_tokenize(text)\n",
    ">>> sent_tokenize_list\n",
    "[“this’s a sent tokenize test.”, ‘this is sent two.’, ‘is this sent three?’, ‘sent 4 is cool!’, “Now it’s your turn.”]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fabb1615-376b-4b18-90e4-bfdb4fce8bda"
    }
   },
   "source": [
    "Tokenize by word: (simpler than sentence tokenizer)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0d428832-0e0e-401f-8744-db1b9fa2d03d"
    }
   },
   "source": [
    ">>> from nltk.tokenize import word_tokenize\n",
    ">>> word_tokenize(‘Hello World.’)\n",
    "[‘Hello’, ‘World’, ‘.’]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "78cd1ee7-a50f-412e-adf5-6035341a4c69"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part of Speech (POS) Tagging\n",
    "\n",
    "\n",
    "* POS is grammatical tagging\n",
    "* Separates into nouns, adjectives, verbs etc.\n",
    "* Can use pre-trained taggers or train yourself\n",
    "\n",
    "Types of POS tags:\n",
    "* JJ: adjective or numeral, ordinal\n",
    "* NNP: noun, proper, singular\n",
    "* IN: preposition or conjunction, subordinating\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "7fab5b42-dabe-48c8-8557-67edd7755575"
    }
   },
   "source": [
    ">>> text = nltk.word_tokenize(“Dive into NLTK: Part-of-speech tagging and POS Tagger”)\n",
    ">>> nltk.pos_tag(text)\n",
    "[(‘Dive’, ‘JJ’), (‘into’, ‘IN’), (‘NLTK’, ‘NNP’), (‘:’, ‘:’), (‘Part-of-speech’, ‘JJ’), (‘tagging’, ‘NN’), (‘and’, ‘CC’), (‘POS’, ‘NNP’), (‘Tagger’, ‘NNP’)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "92f780f0-b790-4b26-87bb-d934e3c7ef82"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stemming\n",
    "\n",
    "Stemming is the the process of reducing a word to its stem through basic suffix stripping. For instance, the stem of the word “lively” is “live”, so running a the statement “She acted lively while helping me today.” through a stemmer (after tokenizing), would return the stems ‘act’, ‘live’, and ‘help’ with their respective words, while the rest of the words would just return the initial input (the words were already at their stem). \n",
    "\n",
    "\n",
    "Some common stemmers:\n",
    "\n",
    "* Snowball : http://www.nltk.org/_modules/nltk/stem/snowball.html\n",
    "\n",
    "* Porter : http://www.nltk.org/_modules/nltk/stem/porter.html\n",
    "\n",
    "* Lancaster : http://www.nltk.org/_modules/nltk/stem/lancaster.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "da42cbda-6b5e-4854-9588-8a134e97b904"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stem of 'expectations' is 'expect'.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "snowball = nltk.stem.snowball.EnglishStemmer()\n",
    "word = 'expectations'\n",
    "print \"The stem of '%s' is '%s'.\" %(word, snowball.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Porter Algorithm\n",
    "\n",
    "Porter's stemming algorithm consists of 5 phases of word reduction applied sequentially.\n",
    "\n",
    "For instance:\n",
    "\n",
    "$$SSES \\rightarrow SS \\\\ caress \\rightarrow care$$\n",
    "\n",
    "<br />\n",
    "$$S \\rightarrow \\\\ cats \\rightarrow cat$$\n",
    "\n",
    "[Read More](http://snowball.tartarus.org/algorithms/porter/stemmer.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0ae3e29d-fe40-411c-ab42-5a2b09d79df4"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A problem that arises is that, for many cases, the stemmers will not return actual words. For instance, the stem of the words “excitement” and “excited” are both “excit”. Stemming is sufficient in many cases of interpreting the meaning of texts, but a better option in terms of meaning, is lemmatization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1bf0f027-a1ed-4740-9ba4-8771035a5656"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lemmatization\n",
    "Lemmatization, on the other hand, is the reducing of a word to a common base word, known as the lemma. For instance, the word “excitement” reduces to the lemma “excite”, but also the words “are”, “am” and “is” reduce to the lemma “be”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Text Generator w/ Markov Chains\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#%load ./Chopra.class.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "./ChopraEdited/Chopra-Deepak-Book-Of-Secrets_Clean.pdf\n",
      "./ChopraEdited/DeepakChopra_Interview_Clean.pdf\n",
      "./ChopraEdited/Chopra-Deepak-the_seven_spiritual_laws_of_yoga_Clean.pdf\n",
      "./ChopraEdited/Chopra-Deepak-superbrain_Clean.pdf\n",
      "./ChopraEdited/DeepakChopra_Quotes_Clean.pdf\n",
      "./ChopraEdited/Chopra-Deepak-the-7-laws-of-success_Clean.pdf\n",
      "./ChopraEdited/Chopra-Deepak-How-To-Know-God_Clean.pdf\n",
      "Done Reading.\n",
      "(258456,) (13050,)\n"
     ]
    }
   ],
   "source": [
    "import extract\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "cleantext = extract.read(directory = \"./ChopraEdited\")\n",
    "\n",
    "stoken = nltk.tokenize.PunktSentenceTokenizer()\n",
    "wtoken = nltk.tokenize.WordPunctTokenizer()\n",
    "s = stoken.tokenize(cleantext)\n",
    "w = wtoken.tokenize(cleantext)\n",
    "print np.shape(w), np.shape(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. My knowledge now is partial; then it will pull me back toward wealth again.\n",
      "\n",
      "2. How far have I gotten to my soul?\n",
      "\n",
      "3. Stage 1: Fight-or-Flight Response: Fear of loss, abandonment Stage 2: Reactive Response Good is clarity, seeing the truth.\n",
      "\n",
      "4. But for these ancient formulations to have any confidence in them.\n",
      "\n",
      "5. The secret cause of suffering hast been examined.\n",
      "\n",
      "6. We don't yet know what that world feels like until you give your allegiance finally to the inner world isn't a mystery.\n",
      "\n",
      "7. Each level of commitment reflects the understanding you are willing to pose the question to yourself, What do I get out of this When you reframe the question asWhat willwe get out of stage one, who should have protected his children.\n",
      "\n",
      "8. The thought I had the strange sensation that it was pervasive.\n",
      "\n",
      "9. If you see yourself as the old melodramas used to promise.\n",
      "\n",
      "10. They make karmic connections and are able to distinguish your observations from your interpretations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mymarkovify\n",
    "\n",
    "#Train our model on the string\n",
    "text_model = mymarkovify.Text(cleantext, state_size=3)\n",
    "\n",
    "n = 10 #number of sentences to be generated\n",
    "for i in range(n):\n",
    "    print \"%s. %s\\n\" % (i+1, text_model.make_sentence(tries=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3bd3fdaf-fbbf-485a-b268-5c2918cc1125"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Text Classification\n",
    "\n",
    "Text Classification is the use of NLTK Classifiers to classify text into categories.\n",
    "\n",
    "\n",
    "NLTK Classifiers:\n",
    "\n",
    "\n",
    "* Naive Bayes Classifier\n",
    "\n",
    "\n",
    "* Maximum Entropy Classifier\n",
    "\n",
    "\n",
    "* Decision Tree\n",
    "\n",
    "\n",
    "* Scikit Learn Wrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "Bayes Theorem : \n",
    "\n",
    "$$ P(C|x) = \\frac{P(x|C) P(C)}{P(x)} $$\n",
    "\n",
    "Naive Bayes Classification :\n",
    "\n",
    "Based on the assumption that all features ${x_1, x_2,......,x_i}$ are conditionally independent, given the category C\n",
    "\n",
    "or, $$ P(x_i|x_1, x_2,..,x_(i-1),x(i+1),..., x_i,C) = P(x_i|C) $$\n",
    "\n",
    "Then, $P(C|x_1,x_2,....,x_i)$ can be computed using Bayes Theorem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Entropy Model\n",
    "\n",
    "The model considers probability distributions closest to empirical data and picks the one with highest entropy.\n",
    "\n",
    "### What does entropy mean?\n",
    "\n",
    "Entropy is measure of uncertainty or 'surprise' in the data. Assumption is that data is likely to have random, unknown elements.\n",
    "\n",
    "### What will have the highest entropy?\n",
    "\n",
    "Usually, uniform distribution will have the highest entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7c6c582e-7ee5-4fdc-8ef0-9839ffc562a7"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applications of Text Classification - \n",
    "\n",
    "\n",
    "* Analyzing and classifying emails, texts and chats for security purposes\n",
    "\n",
    "\n",
    "* Data acquisition from social media posts for advertising\n",
    "\n",
    "\n",
    "* Analysis of speech patterns and transcripts for academic research (grammar development, language research, psychology, etc.)\n",
    "\n",
    "\n",
    "* Integrating NLP techniques with Artificial Intelligence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "6ddad21f-79d6-414f-80f2-8f5fcd7dd99e"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbpresent": {
   "slides": {},
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
