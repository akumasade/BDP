{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os, string, json, textract, mymarkovify\n",
    "import numpy as np\n",
    "\n",
    "# Directory from which we are going to train our model on\n",
    "\n",
    "#directory = \"./twitter_samples\"\n",
    "directory = \"./ChopraEdited\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_chopra(path):\n",
    "    \"\"\"\n",
    "    Function to extract all text from a file as a single string\n",
    "    (Also removes non-ascii characters)\n",
    "    \"\"\"\n",
    "    \n",
    "    #create set of printable characters for filtering non-ascii charaters\n",
    "    printable = set(string.printable)\n",
    "    \n",
    "    #only reading from pdf files\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        text = textract.process(path)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    text.replace(\"\\n\", \" \")\n",
    "    text.replace(\"\\t\", \" \")\n",
    "    text.replace(\"\\s\", \" \")\n",
    "    text.replace(\"\\r\", \" \")\n",
    "    filter(lambda x: x in printable, text)\n",
    "    #' '.join(i if ord(i)<128 else ' ' for i in text  )\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_tweets(path):\n",
    "    \"\"\"\n",
    "    Function specifically made to read twitter_samples json files\n",
    "    \"\"\"\n",
    "    dict_list = []\n",
    "    \n",
    "    for line in open(path):\n",
    "        loaded = json.loads(line)\n",
    "        dict_list.append(loaded)\n",
    "        \n",
    "    text = \"\"\n",
    "    for item in dict_list:\n",
    "        try:\n",
    "            tweet = item[\"text\"]\n",
    "            filter(lambda x: x in printable, tweet)\n",
    "            text += text\n",
    "        except UnicodeEncodeError:\n",
    "            pass\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "./ChopraEdited/Chopra-Deepak-How-To-Know-God_Clean.pdf\n",
      "./ChopraEdited/Chopra-Deepak-the_seven_spiritual_laws_of_yoga_Clean.pdf\n",
      "./ChopraEdited/DeepakChopra_Interview_Clean.pdf\n",
      "./ChopraEdited/Chopra-Deepak-Book-Of-Secrets_Clean.pdf\n",
      "./ChopraEdited/Chopra-Deepak-the-7-laws-of-success_Clean.pdf\n",
      "./ChopraEdited/DeepakChopra_Quotes_Clean.pdf\n",
      "./ChopraEdited/Chopra-Deepak-superbrain_Clean.pdf\n",
      "Done Reading.\n"
     ]
    }
   ],
   "source": [
    "# Extract texts as one big string (could change this later)\n",
    "\n",
    "alltext = \"\"\n",
    "\n",
    "print \"Reading files...\"\n",
    "for filename in os.listdir(directory):\n",
    "    \n",
    "    path = os.path.join(directory,filename)\n",
    "    \n",
    "    if (directory.find(\"twitter_samples\") != -1 ) and filename.endswith(\".json\"):\n",
    "        print path\n",
    "        text = extract_tweets(path)\n",
    "        alltext = alltext + \". \" + text\n",
    "    \n",
    "    elif (directory.find(\"ChopraEdited\") != -1) and filename.endswith(\".pdf\"):\n",
    "        print path\n",
    "        text = extract_chopra(path)\n",
    "        alltext += \" \" + text\n",
    "        \n",
    "\n",
    "print \"Done Reading.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stoken = nltk.tokenize.PunktSentenceTokenizer()\n",
    "\n",
    "# printable = set(string.printable)\n",
    "# filter(lambda x: x not in printable, alltext)\n",
    "\n",
    "# print np.size(alltext) \n",
    "# #print alltext\n",
    "\n",
    "# for i,j in enumerate(alltext):\n",
    "#     if j not in printable: \n",
    "#         print \"oops \", i, j\n",
    "#         break\n",
    "        \n",
    "\n",
    "# s = stoken.tokenize(alltext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now onto the Markov Chains\n",
    "#print type(alltext)\n",
    "text_model = mymarkovify.Text(alltext, state_size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Music is a glorious pursuit on its own, but the side that wants to express the sacred purpose for which you feel joy in the face of adversity.\n",
      "\n",
      "2. The Vertical Assembly Building at the Kennedy Space Center is tall enough to hold up your hand and realize that it wasn't a scream I had heard but a wail.\n",
      "\n",
      "3. Over the next few minutes, practice the So Hum meditation described below will help take your awareness back to the existence of the mind.\n",
      "\n",
      "4. The absolute break between life and death merge is always here with us, and only the faintest glimmer of sunlight still penetrated from the outside world must be far more powerful.\n",
      "\n",
      "5. Acceptance:I will spend five minutes thinking about the shock and pain of dying that way.â€\n",
      "\n",
      "6. How far have I gotten in the past or something you are anticipating happening in the future.\n",
      "\n",
      "7. Clues are left to tell us when we are inspired, we don't act from need at all.\n",
      "\n",
      "8. Pay attention to your breathing.\n",
      "\n",
      "9. This voice is a relic of the past, the accumulation of material possessions loses its hold on you and lending you its support.\n",
      "\n",
      "10. At the level of consciousness rises.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print \"%s. %s\\n\" % (i+1, text_model.make_sentence(tries=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
