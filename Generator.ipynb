{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os, string, json, textract, mymarkovify\n",
    "#import numpy as np\n",
    "\n",
    "# Directory from which we are going to train our model on\n",
    "\n",
    "#directory = \"./twitter_samples\"\n",
    "directory = \"./ChopraEdited\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_chopra(path):\n",
    "    \"\"\"\n",
    "    Function to extract all text from a file as a single string\n",
    "    (Also removes non-ascii characters)\n",
    "    \"\"\"\n",
    "    \n",
    "    #create set of printable characters for filtering non-ascii charaters\n",
    "    printable = set(string.printable)\n",
    "    \n",
    "    #only reading from pdf files\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        text = textract.process(path, endcoding='ascii')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    text.replace(\"\\n\", \" \")\n",
    "    text.replace(\"\\t\", \" \")\n",
    "    text.replace(\"\\s\", \" \")\n",
    "    text.replace(\"\\r\", \" \")\n",
    "    filter(lambda x: x in printable, text)\n",
    "    ' '.join(\" \" if ord(i)>128 else i for i in text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_tweets(path):\n",
    "    \"\"\"\n",
    "    Function specifically made to read twitter_samples json files\n",
    "    \"\"\"\n",
    "    dict_list = []\n",
    "    \n",
    "    for line in open(path):\n",
    "        loaded = json.loads(line)\n",
    "        dict_list.append(loaded)\n",
    "        \n",
    "    text = \"\"\n",
    "    for item in dict_list:\n",
    "        try:\n",
    "            tweet = item[\"text\"]\n",
    "            filter(lambda x: x in printable, tweet)\n",
    "            text += text\n",
    "        except UnicodeEncodeError:\n",
    "            pass\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "./ChopraEdited/Chopra-Deepak-How-To-Know-God_Clean.pdf\n",
      "Done Reading.\n",
      "./ChopraEdited/Chopra-Deepak-the_seven_spiritual_laws_of_yoga_Clean.pdf\n",
      "Done Reading.\n",
      "./ChopraEdited/DeepakChopra_Interview_Clean.pdf\n",
      "Done Reading.\n",
      "./ChopraEdited/Chopra-Deepak-Book-Of-Secrets_Clean.pdf\n",
      "Done Reading.\n",
      "./ChopraEdited/Chopra-Deepak-the-7-laws-of-success_Clean.pdf\n",
      "Done Reading.\n",
      "./ChopraEdited/DeepakChopra_Quotes_Clean.pdf\n",
      "Done Reading.\n",
      "./ChopraEdited/Chopra-Deepak-superbrain_Clean.pdf\n",
      "Done Reading.\n"
     ]
    }
   ],
   "source": [
    "# Extract texts as one big string (could change this later)\n",
    "\n",
    "alltext = \"\"\n",
    "\n",
    "print \"Reading files...\"\n",
    "for filename in os.listdir(directory):\n",
    "    \n",
    "    path = os.path.join(directory,filename)\n",
    "    \n",
    "    if (directory.find(\"twitter_samples\") != -1 ) and filename.endswith(\".json\"):\n",
    "        print path\n",
    "        text = extract_tweets(path)\n",
    "        alltext = alltext + \". \" + text\n",
    "    \n",
    "    elif (directory.find(\"ChopraEdited\") != -1) and filename.endswith(\".pdf\"):\n",
    "        print path\n",
    "        text = extract_chopra(path)\n",
    "        alltext += \" \" + text\n",
    "        \n",
    "\n",
    "\n",
    "print \"Done Reading.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13051,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For some reason the ASCII filter didn't work,\n",
    "so now we're just manually removing the non-ASCII chars.\n",
    "\"\"\"\n",
    "\n",
    "cleanstring = \"\"\n",
    "prev = 0\n",
    "for i,j in enumerate(alltext):\n",
    "    if ord(j) > 128: \n",
    "        cleanstring += alltext[prev:i-1]\n",
    "        prev = i+1\n",
    "        \n",
    "\n",
    "stoken = nltk.tokenize.PunktSentenceTokenizer()\n",
    "s = stoken.tokenize(cleanstring)\n",
    "print np.shape(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now onto the Markov Chains\n",
    "#print type(alltext)\n",
    "text_model = mymarkovify.Text(cleanstring, state_size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. It is the unfolding of God is too ghostly to be relied upon.\n",
      "\n",
      "2. Yet surrendering to someone else follows the same coursif you let it.\n",
      "\n",
      "3. Although it was understood that this was a gesture of ultimate goodness.\n",
      "\n",
      "4. There is reason to believe in random events and chance causation?\n",
      "\n",
      "5. Studies have shown that in patients with recent heart attacks, men who believe that they deserve everything they have earned, no matter by what means.\n",
      "\n",
      "6. Stated simply, the Law of Least Effort tells us that if you want to know the patient personally, or even know their names.\n",
      "\n",
      "7. In this chapter, we will apply the Seven Spiritual Laws of Yoga Teacher Training Program.\n",
      "\n",
      "8. The circle closes, and the mystic experiences himself as the one where a woman saint outside Bombay known to her followers simply as Mother.\n",
      "\n",
      "9. Hold this pose for ten seconds, then return your left leg until you can hook your toes inside your left calf muscle.\n",
      "\n",
      "10. A healing relationship is based on fear and insecurity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print \"%s. %s\\n\" % (i+1, text_model.make_sentence(tries=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
