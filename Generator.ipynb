{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os, string, json, textract, mymarkovify\n",
    "import numpy as np\n",
    "\n",
    "# Directory from which we are going to train our model on\n",
    "\n",
    "#directory = \"./twitter_samples\"\n",
    "directory = \"./ChopraEdited\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_chopra(path):\n",
    "    \"\"\"\n",
    "    Function to extract all text from a file as a single string\n",
    "    (Also removes non-ascii characters)\n",
    "    \"\"\"\n",
    "    \n",
    "    #create set of printable characters for filtering non-ascii charaters\n",
    "    printable = set(string.printable)\n",
    "    \n",
    "    #only reading from pdf files\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        text = textract.process(path, endcoding='ascii')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    text.replace(\"\\n\", \" \")\n",
    "    text.replace(\"\\t\", \" \")\n",
    "    text.replace(\"\\s\", \" \")\n",
    "    text.replace(\"\\r\", \" \")\n",
    "    filter(lambda x: x in printable, text)\n",
    "    ' '.join(\" \" if ord(i)>128 else i for i in text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_tweets(path):\n",
    "    \"\"\"\n",
    "    Function specifically made to read twitter_samples json files\n",
    "    \"\"\"\n",
    "    dict_list = []\n",
    "    \n",
    "    for line in open(path):\n",
    "        loaded = json.loads(line)\n",
    "        dict_list.append(loaded)\n",
    "        \n",
    "    text = \"\"\n",
    "    for item in dict_list:\n",
    "        try:\n",
    "            tweet = item[\"text\"]\n",
    "            filter(lambda x: x in printable, tweet)\n",
    "            text += text\n",
    "        except UnicodeEncodeError:\n",
    "            pass\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "./ChopraEdited/Chopra-Deepak-How-To-Know-God_Clean.pdf\n",
      "./ChopraEdited/Chopra-Deepak-the_seven_spiritual_laws_of_yoga_Clean.pdf\n",
      "./ChopraEdited/DeepakChopra_Interview_Clean.pdf\n",
      "./ChopraEdited/Chopra-Deepak-Book-Of-Secrets_Clean.pdf\n",
      "./ChopraEdited/Chopra-Deepak-the-7-laws-of-success_Clean.pdf\n",
      "./ChopraEdited/DeepakChopra_Quotes_Clean.pdf\n",
      "./ChopraEdited/Chopra-Deepak-superbrain_Clean.pdf\n",
      "Done Reading.\n"
     ]
    }
   ],
   "source": [
    "# Extract texts as one big string (could change this later)\n",
    "\n",
    "alltext = \"\"\n",
    "\n",
    "print \"Reading files...\"\n",
    "for filename in os.listdir(directory):\n",
    "    \n",
    "    path = os.path.join(directory,filename)\n",
    "    \n",
    "    if (directory.find(\"twitter_samples\") != -1 ) and filename.endswith(\".json\"):\n",
    "        print path\n",
    "        text = extract_tweets(path)\n",
    "        alltext = alltext + \". \" + text\n",
    "    \n",
    "    elif (directory.find(\"ChopraEdited\") != -1) and filename.endswith(\".pdf\"):\n",
    "        print path\n",
    "        text = extract_chopra(path)\n",
    "        alltext += \" \" + text\n",
    "        \n",
    "\n",
    "\n",
    "        print \"Done Reading.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13051,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For some reason the ASCII filter didn't work,\n",
    "so now we're just manually removing the non-ASCII chars.\n",
    "\"\"\"\n",
    "\n",
    "cleanstring = \"\"\n",
    "prev = 0\n",
    "for i,j in enumerate(alltext):\n",
    "    if ord(j) > 128: \n",
    "        cleanstring += alltext[prev:i-1]\n",
    "        prev = i+1\n",
    "        \n",
    "\n",
    "stoken = nltk.tokenize.PunktSentenceTokenizer()\n",
    "s = stoken.tokenize(newstring)\n",
    "print np.shape(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now onto the Markov Chains\n",
    "#print type(alltext)\n",
    "text_model = mymarkovify.Text(cleanstring, state_size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. That person is a good reason.\n",
      "\n",
      "2. He became convinced, however, that she was destined to wed a man whom she considered no more than a system of mindful surrender.\n",
      "\n",
      "3. The fact that the basis of samskara without knowing that they do.\n",
      "\n",
      "4. It isn't a cold, heartless detachment but a kind of mental sharing, whether it is inherent.\n",
      "\n",
      "5. To master pure awareness, you must learn how to feel your way into the shadow.\n",
      "\n",
      "6. But as Generated by ABC Amber LIT Converter, http://www.processtext.com/abclit.html as well as your own.\n",
      "\n",
      "7. God is no more need for sorrow.\n",
      "\n",
      "8. The reason we cat let raw sensation go without interpreting it is that occurs at death, I believe it deserves to be called a miracle.\n",
      "\n",
      "9. The world at its essential core is a quantum mirage, winking in and out of the bad choices and one bad thing that came out of the conditioned mind and opens up access to the field of pure potentiality.\n",
      "\n",
      "10. The evil that results can be seen as aspects of yourself, you are actually seeing faces of mythical types.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print \"%s. %s\\n\" % (i+1, text_model.make_sentence(tries=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
